{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Retrieval on CISI Dataset\n",
    "\n",
    "This notebook implements a Vector Space Model (VSM) to retrieve documents from the CISI dataset and evaluates its performance using P@10, MAP, and Recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Downloads\n",
    "nltk.download('stopwords', quiet=True)\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "# Assuming cisi_data is in the same directory as this notebook\n",
    "DATA_DIR = os.path.join(os.getcwd(), 'cisi_data')\n",
    "\n",
    "FILES = {\n",
    "    'docs': os.path.join(DATA_DIR, 'CISI.ALL'),\n",
    "    'queries': os.path.join(DATA_DIR, 'CISI.QRY'),\n",
    "    'rels': os.path.join(DATA_DIR, 'CISI.REL')\n",
    "}\n",
    "\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z0-9\\s]', ' ', text)\n",
    "    tokens = [t for t in text.split() if t not in STOPWORDS]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CISIParser:\n",
    "    @staticmethod\n",
    "    def _parse_cisi_content(file_path, target_tags):\n",
    "        if not os.path.exists(file_path):\n",
    "            raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "            \n",
    "        with open(file_path, 'r') as f:\n",
    "            content = f.read()\n",
    "\n",
    "        parsed_data = {}\n",
    "        items = content.split('.I ')\n",
    "\n",
    "        for item in items[1:]:  # Skip empty preamble\n",
    "            lines = item.split('\\n')\n",
    "            try:\n",
    "                obj_id = int(lines[0].strip())\n",
    "            except ValueError:\n",
    "                continue  # Skip malformed IDs\n",
    "\n",
    "            collected_text = []\n",
    "            current_tag = None\n",
    "\n",
    "            for line in lines:\n",
    "                if line.startswith('.'):\n",
    "                    current_tag = line[:2]\n",
    "                    continue\n",
    "\n",
    "                if current_tag in target_tags:\n",
    "                    collected_text.append(line)\n",
    "\n",
    "            parsed_data[obj_id] = \" \".join(collected_text).strip()\n",
    "\n",
    "        return parsed_data\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_docs(file_path):\n",
    "        return CISIParser._parse_cisi_content(file_path, target_tags=['.T', '.W'])\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_titles(file_path):\n",
    "        return CISIParser._parse_cisi_content(file_path, target_tags=['.T'])\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_queries(file_path):\n",
    "        return CISIParser._parse_cisi_content(file_path, target_tags=['.W'])\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_rels(file_path):\n",
    "        rels = defaultdict(set)\n",
    "        if not os.path.exists(file_path):\n",
    "             raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "             \n",
    "        with open(file_path, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 2:\n",
    "                    try:\n",
    "                        qid = int(parts[0])\n",
    "                        doc_id = int(parts[1])\n",
    "                        rels[qid].add(doc_id)\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "        return rels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorSpaceModel:\n",
    "    def __init__(self, docs):\n",
    "        self.doc_ids = list(docs.keys())\n",
    "        self.corpus = [docs[did] for did in self.doc_ids]\n",
    "        self.vectorizer = TfidfVectorizer(\n",
    "            preprocessor=preprocess_text,\n",
    "            stop_words=None  # Preprocessing handles this\n",
    "        )\n",
    "        self.doc_vectors = self.vectorizer.fit_transform(self.corpus)\n",
    "\n",
    "    def retrieve(self, query_text):\n",
    "        q_vec = self.vectorizer.transform([query_text])\n",
    "        scores = cosine_similarity(q_vec, self.doc_vectors).flatten()\n",
    "        ranked_indices = scores.argsort()[::-1]\n",
    "        results = []\n",
    "        for idx in ranked_indices:\n",
    "            if scores[idx] > 0:\n",
    "                results.append((self.doc_ids[idx], scores[idx]))\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "def calculate_map(retrieved, relevant):\n",
    "    if not relevant: return 0.0\n",
    "    score = 0.0\n",
    "    hits = 0.0\n",
    "    for i, (doc_id, _) in enumerate(retrieved):\n",
    "        if doc_id in relevant:\n",
    "            hits += 1.0\n",
    "            score += hits / (i + 1)\n",
    "    return score / len(relevant)\n",
    "\n",
    "def calculate_p10(retrieved, relevant):\n",
    "    if not relevant: return 0.0\n",
    "    top_10 = retrieved[:10]\n",
    "    hits = sum(1 for doc_id, _ in top_10 if doc_id in relevant)\n",
    "    return hits / 10.0\n",
    "\n",
    "def calculate_recall(retrieved, relevant):\n",
    "    if not relevant: return 0.0\n",
    "    hits = sum(1 for doc_id, _ in retrieved if doc_id in relevant)\n",
    "    return hits / len(relevant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CISI Dataset...\n",
      "Loaded 1460 docs, 112 queries, 76 rel sets.\n",
      "\n",
      "Initializing Vector Space Model...\n",
      "\n",
      "Running Retrieval & Evaluation...\n",
      "========================================\n",
      "EVALUATION RESULTS (VSM)\n",
      "========================================\n",
      "MAP       : 0.1981\n",
      "P@10      : 0.3197\n",
      "Recall    : 0.9043\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"Loading CISI Dataset...\")\n",
    "    try:\n",
    "        docs = CISIParser.parse_docs(FILES['docs'])\n",
    "        queries = CISIParser.parse_queries(FILES['queries'])\n",
    "        rels = CISIParser.parse_rels(FILES['rels'])\n",
    "        print(f\"Loaded {len(docs)} docs, {len(queries)} queries, {len(rels)} rel sets.\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(\"Please check your 'cisi_data' directory path.\")\n",
    "        docs = {}\n",
    "\n",
    "    if docs:\n",
    "        print(\"\\nInitializing Vector Space Model...\")\n",
    "        vsm = VectorSpaceModel(docs)\n",
    "\n",
    "        print(\"\\nRunning Retrieval & Evaluation...\")\n",
    "        map_scores = []\n",
    "        p10_scores = []\n",
    "        recall_scores = []\n",
    "\n",
    "        # Iterate over queries that have relevance judgments\n",
    "        active_queries = [q for q in queries if q in rels]\n",
    "\n",
    "        for qid in active_queries:\n",
    "            query_text = queries[qid]\n",
    "            relevant_docs = rels[qid]\n",
    "            \n",
    "            # Retrieve\n",
    "            results = vsm.retrieve(query_text)\n",
    "            \n",
    "            # Calculate Metrics\n",
    "            map_s = calculate_map(results, relevant_docs)\n",
    "            p10_s = calculate_p10(results, relevant_docs)\n",
    "            rec_s = calculate_recall(results, relevant_docs)\n",
    "            \n",
    "            map_scores.append(map_s)\n",
    "            p10_scores.append(p10_s)\n",
    "            recall_scores.append(rec_s)\n",
    "\n",
    "        mean_map = np.mean(map_scores) if map_scores else 0\n",
    "        mean_p10 = np.mean(p10_scores) if p10_scores else 0\n",
    "        mean_recall = np.mean(recall_scores) if recall_scores else 0\n",
    "\n",
    "        print(\"=\"*40)\n",
    "        print(\"EVALUATION RESULTS (VSM)\")\n",
    "        print(\"=\"*40)\n",
    "        print(f\"MAP       : {mean_map:.4f}\")\n",
    "        print(f\"P@10      : {mean_p10:.4f}\")\n",
    "        print(f\"Recall    : {mean_recall:.4f}\")\n",
    "        print(\"=\"*40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
